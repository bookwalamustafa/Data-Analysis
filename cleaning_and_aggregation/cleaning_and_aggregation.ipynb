{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWL1iSNqF4kn"
   },
   "source": [
    "# INFO 212: Data Science Programming 1\n",
    "## CCI at Drexel University\n",
    "\n",
    "\n",
    "## Week 8 Lab : Cleaning and Aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "ceh3U4Tl0fTL"
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xJvkSWVuEF9"
   },
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwz5-9J7uB6x"
   },
   "source": [
    "1. Download and upload the nba-2016.csv. Create a DataFrame df from the data set. Show information of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "eOjNIrv5GPoL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of Dataframe: Index(['Date', 'Start (ET)', 'Visitor/Neutral', 'PTS', 'Home/Neutral', 'PTS.1',\n",
      "       'Unnamed: 6', 'Unnamed: 7', 'Attend.', 'Notes'],\n",
      "      dtype='object')\n",
      "\n",
      "First five rows of Dataframe:               Date Start (ET)       Visitor/Neutral  PTS  \\\n",
      "0  Tue Oct 27 2015      8:00p   Cleveland Cavaliers   95   \n",
      "1  Tue Oct 27 2015      8:00p       Detroit Pistons  106   \n",
      "2  Tue Oct 27 2015     10:30p  New Orleans Pelicans   95   \n",
      "3  Wed Oct 28 2015      7:00p    Washington Wizards   88   \n",
      "4  Wed Oct 28 2015      7:30p    Philadelphia 76ers   95   \n",
      "\n",
      "            Home/Neutral  PTS.1 Unnamed: 6 Unnamed: 7  Attend. Notes  \n",
      "0          Chicago Bulls     97  Box Score        NaN    21957   NaN  \n",
      "1          Atlanta Hawks     94  Box Score        NaN    19187   NaN  \n",
      "2  Golden State Warriors    111  Box Score        NaN    19596   NaN  \n",
      "3          Orlando Magic     87  Box Score        NaN    18846   NaN  \n",
      "4         Boston Celtics    112  Box Score        NaN    18624   NaN  \n",
      "\n",
      "               PTS        PTS.1       Attend.\n",
      "count  1316.000000  1316.000000   1316.000000\n",
      "mean    100.971884   103.999240  17970.163374\n",
      "std      11.758921    11.705285   2288.311062\n",
      "min      68.000000    68.000000   9153.000000\n",
      "25%      93.000000    96.000000  16983.000000\n",
      "50%     101.000000   104.000000  18418.000000\n",
      "75%     109.000000   112.000000  19600.000000\n",
      "max     147.000000   144.000000  23152.000000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/mustafabookwala/Desktop/Drexel/Pre-Junior/Fall 2024/INFO 212/Week 8/nba-2016(3).csv\")  # Loading the dataframe\n",
    "print(f\"Columns of Dataframe: {df.columns}\\n\")  # Displaying Column Names\n",
    "print(f\"First five rows of Dataframe: {df.head()}\\n\")  # Displaying first five entries\n",
    "print(df.describe())  # Displaying statistical information about numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9r3suT-36fgP"
   },
   "source": [
    "2. Does the dataset have mssing values? Compute the percentage of missing values overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "2a17-UGl6sUT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total % of missing values in dataframe: 2.09%\n"
     ]
    }
   ],
   "source": [
    "df = df.rename(columns={'PTS': 'Visitor PTS', 'PTS.1': 'Home PTS', 'Unnamed: 6': 'Score Type', 'Unnamed: 7': 'OT'})  # Renaming certain unnamed and repetitive named columns\n",
    "        \n",
    "print(f\"Total % of missing values in dataframe: {round(((df.isnull().sum().sum())/(df.shape[0] * df.shape[1])) * 100, 2)}%\")  # Calculating and printing the number of null values in the entire dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yr7tQZ8I6uL0"
   },
   "source": [
    "3. List the number and percentage of missing values for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "id": "yG9KBOQe6su-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1 has 2 missing values, which is 18.18%\n",
      "Row 2 has 2 missing values, which is 18.18%\n",
      "Row 3 has 2 missing values, which is 18.18%\n",
      "Row 4 has 2 missing values, which is 18.18%\n",
      "Row 5 has 2 missing values, which is 18.18%\n",
      "Row 6 has 2 missing values, which is 18.18%\n",
      "Row 7 has 2 missing values, which is 18.18%\n",
      "Row 8 has 2 missing values, which is 18.18%\n",
      "Row 9 has 2 missing values, which is 18.18%\n",
      "Row 10 has 2 missing values, which is 18.18%\n",
      "Row 11 has 2 missing values, which is 18.18%\n",
      "Row 12 has 2 missing values, which is 18.18%\n",
      "Row 13 has 2 missing values, which is 18.18%\n",
      "Row 14 has 2 missing values, which is 18.18%\n",
      "Row 15 has 2 missing values, which is 18.18%\n",
      "Row 16 has 2 missing values, which is 18.18%\n",
      "Row 17 has 2 missing values, which is 18.18%\n",
      "Row 18 has 2 missing values, which is 18.18%\n",
      "Row 19 has 2 missing values, which is 18.18%\n",
      "Row 20 has 2 missing values, which is 18.18%\n",
      "Row 21 has 2 missing values, which is 18.18%\n",
      "Row 22 has 2 missing values, which is 18.18%\n",
      "Row 23 has 1 missing values, which is 9.09%\n",
      "Row 24 has 1 missing values, which is 9.09%\n",
      "Row 25 has 1 missing values, which is 9.09%\n",
      "Row 26 has 1 missing values, which is 9.09%\n",
      "Row 27 has 1 missing values, which is 9.09%\n",
      "Row 28 has 1 missing values, which is 9.09%\n",
      "Row 29 has 1 missing values, which is 9.09%\n",
      "Row 30 has 1 missing values, which is 9.09%\n",
      "Row 31 has 1 missing values, which is 9.09%\n",
      "Row 32 has 1 missing values, which is 9.09%\n",
      "Row 33 has 1 missing values, which is 9.09%\n",
      "Row 34 has 1 missing values, which is 9.09%\n",
      "Row 35 has 1 missing values, which is 9.09%\n",
      "Row 36 has 1 missing values, which is 9.09%\n",
      "Row 37 has 1 missing values, which is 9.09%\n",
      "Row 38 has 1 missing values, which is 9.09%\n",
      "Row 39 has 1 missing values, which is 9.09%\n",
      "Row 40 has 1 missing values, which is 9.09%\n",
      "Row 41 has 1 missing values, which is 9.09%\n",
      "Row 42 has 1 missing values, which is 9.09%\n",
      "Row 43 has 1 missing values, which is 9.09%\n",
      "Row 44 has 1 missing values, which is 9.09%\n",
      "Row 45 has 1 missing values, which is 9.09%\n",
      "Row 46 has 1 missing values, which is 9.09%\n",
      "Row 47 has 1 missing values, which is 9.09%\n",
      "Row 48 has 1 missing values, which is 9.09%\n",
      "Row 49 has 1 missing values, which is 9.09%\n",
      "Row 50 has 1 missing values, which is 9.09%\n",
      "Row 51 has 1 missing values, which is 9.09%\n",
      "Row 52 has 1 missing values, which is 9.09%\n",
      "Row 53 has 1 missing values, which is 9.09%\n",
      "Row 54 has 1 missing values, which is 9.09%\n",
      "Row 55 has 1 missing values, which is 9.09%\n",
      "Row 56 has 1 missing values, which is 9.09%\n",
      "Row 57 has 1 missing values, which is 9.09%\n",
      "Row 58 has 1 missing values, which is 9.09%\n",
      "Row 59 has 1 missing values, which is 9.09%\n",
      "Row 60 has 1 missing values, which is 9.09%\n",
      "Row 61 has 1 missing values, which is 9.09%\n",
      "Row 62 has 1 missing values, which is 9.09%\n",
      "Row 63 has 1 missing values, which is 9.09%\n",
      "Row 64 has 1 missing values, which is 9.09%\n",
      "Row 65 has 1 missing values, which is 9.09%\n",
      "Row 66 has 1 missing values, which is 9.09%\n",
      "Row 67 has 1 missing values, which is 9.09%\n",
      "Row 68 has 1 missing values, which is 9.09%\n",
      "Row 69 has 1 missing values, which is 9.09%\n",
      "Row 70 has 1 missing values, which is 9.09%\n",
      "Row 71 has 1 missing values, which is 9.09%\n",
      "Row 72 has 1 missing values, which is 9.09%\n",
      "Row 73 has 1 missing values, which is 9.09%\n",
      "Row 74 has 1 missing values, which is 9.09%\n",
      "Row 75 has 1 missing values, which is 9.09%\n",
      "Row 76 has 1 missing values, which is 9.09%\n",
      "Row 77 has 1 missing values, which is 9.09%\n",
      "Row 78 has 1 missing values, which is 9.09%\n",
      "Row 79 has 1 missing values, which is 9.09%\n",
      "Row 80 has 1 missing values, which is 9.09%\n",
      "Row 81 has 1 missing values, which is 9.09%\n",
      "Row 82 has 1 missing values, which is 9.09%\n",
      "Row 83 has 1 missing values, which is 9.09%\n",
      "Row 84 has 1 missing values, which is 9.09%\n",
      "Row 85 has 1 missing values, which is 9.09%\n",
      "Row 86 has 1 missing values, which is 9.09%\n",
      "Row 87 has 1 missing values, which is 9.09%\n",
      "Row 88 has 1 missing values, which is 9.09%\n",
      "Row 89 has 1 missing values, which is 9.09%\n",
      "Row 90 has 1 missing values, which is 9.09%\n",
      "Row 91 has 1 missing values, which is 9.09%\n",
      "Row 92 has 1 missing values, which is 9.09%\n",
      "Row 93 has 1 missing values, which is 9.09%\n",
      "Row 94 has 1 missing values, which is 9.09%\n",
      "Row 95 has 1 missing values, which is 9.09%\n",
      "Row 96 has 1 missing values, which is 9.09%\n",
      "Row 97 has 1 missing values, which is 9.09%\n",
      "Row 98 has 1 missing values, which is 9.09%\n",
      "Row 99 has 1 missing values, which is 9.09%\n",
      "Row 100 has 1 missing values, which is 9.09%\n",
      "Row 101 has 1 missing values, which is 9.09%\n",
      "Row 102 has 1 missing values, which is 9.09%\n",
      "Row 103 has 1 missing values, which is 9.09%\n",
      "Row 104 has 1 missing values, which is 9.09%\n",
      "Row 105 has 1 missing values, which is 9.09%\n",
      "Row 106 has 1 missing values, which is 9.09%\n",
      "Row 107 has 1 missing values, which is 9.09%\n",
      "Row 108 has 1 missing values, which is 9.09%\n",
      "Row 109 has 1 missing values, which is 9.09%\n",
      "Row 110 has 1 missing values, which is 9.09%\n",
      "Row 111 has 1 missing values, which is 9.09%\n",
      "Row 112 has 1 missing values, which is 9.09%\n",
      "Row 113 has 1 missing values, which is 9.09%\n",
      "Row 114 has 1 missing values, which is 9.09%\n",
      "Row 115 has 1 missing values, which is 9.09%\n",
      "Row 116 has 1 missing values, which is 9.09%\n",
      "Row 117 has 1 missing values, which is 9.09%\n",
      "Row 118 has 1 missing values, which is 9.09%\n",
      "Row 119 has 1 missing values, which is 9.09%\n",
      "Row 120 has 1 missing values, which is 9.09%\n",
      "Row 121 has 1 missing values, which is 9.09%\n",
      "Row 122 has 1 missing values, which is 9.09%\n",
      "Row 123 has 1 missing values, which is 9.09%\n",
      "Row 124 has 1 missing values, which is 9.09%\n",
      "Row 125 has 1 missing values, which is 9.09%\n",
      "Row 126 has 1 missing values, which is 9.09%\n",
      "Row 127 has 1 missing values, which is 9.09%\n",
      "Row 128 has 1 missing values, which is 9.09%\n",
      "Row 129 has 1 missing values, which is 9.09%\n",
      "Row 130 has 1 missing values, which is 9.09%\n",
      "Row 131 has 1 missing values, which is 9.09%\n",
      "Row 132 has 1 missing values, which is 9.09%\n",
      "Row 133 has 1 missing values, which is 9.09%\n",
      "Row 134 has 1 missing values, which is 9.09%\n",
      "Row 135 has 1 missing values, which is 9.09%\n",
      "Row 136 has 1 missing values, which is 9.09%\n",
      "Row 137 has 1 missing values, which is 9.09%\n",
      "Row 138 has 1 missing values, which is 9.09%\n",
      "Row 139 has 1 missing values, which is 9.09%\n",
      "Row 140 has 1 missing values, which is 9.09%\n",
      "Row 141 has 1 missing values, which is 9.09%\n",
      "Row 142 has 1 missing values, which is 9.09%\n",
      "Row 143 has 1 missing values, which is 9.09%\n",
      "Row 144 has 1 missing values, which is 9.09%\n",
      "Row 145 has 1 missing values, which is 9.09%\n",
      "Row 146 has 1 missing values, which is 9.09%\n",
      "Row 147 has 1 missing values, which is 9.09%\n",
      "Row 148 has 1 missing values, which is 9.09%\n",
      "Row 149 has 1 missing values, which is 9.09%\n",
      "Row 150 has 1 missing values, which is 9.09%\n",
      "Row 151 has 1 missing values, which is 9.09%\n",
      "Row 152 has 1 missing values, which is 9.09%\n",
      "Row 153 has 1 missing values, which is 9.09%\n",
      "Row 154 has 1 missing values, which is 9.09%\n",
      "Row 155 has 1 missing values, which is 9.09%\n",
      "Row 156 has 1 missing values, which is 9.09%\n",
      "Row 157 has 1 missing values, which is 9.09%\n",
      "Row 158 has 1 missing values, which is 9.09%\n",
      "Row 159 has 1 missing values, which is 9.09%\n",
      "Row 160 has 1 missing values, which is 9.09%\n",
      "Row 161 has 1 missing values, which is 9.09%\n",
      "Row 162 has 1 missing values, which is 9.09%\n",
      "Row 163 has 1 missing values, which is 9.09%\n",
      "Row 164 has 1 missing values, which is 9.09%\n",
      "Row 165 has 1 missing values, which is 9.09%\n",
      "Row 166 has 1 missing values, which is 9.09%\n",
      "Row 167 has 1 missing values, which is 9.09%\n",
      "Row 168 has 1 missing values, which is 9.09%\n",
      "Row 169 has 1 missing values, which is 9.09%\n",
      "Row 170 has 1 missing values, which is 9.09%\n",
      "Row 171 has 1 missing values, which is 9.09%\n",
      "Row 172 has 1 missing values, which is 9.09%\n",
      "Row 173 has 1 missing values, which is 9.09%\n",
      "Row 174 has 1 missing values, which is 9.09%\n",
      "Row 175 has 1 missing values, which is 9.09%\n",
      "Row 176 has 1 missing values, which is 9.09%\n",
      "Row 177 has 1 missing values, which is 9.09%\n",
      "Row 178 has 1 missing values, which is 9.09%\n",
      "Row 179 has 1 missing values, which is 9.09%\n",
      "Row 180 has 1 missing values, which is 9.09%\n",
      "Row 181 has 1 missing values, which is 9.09%\n",
      "Row 182 has 1 missing values, which is 9.09%\n",
      "Row 183 has 1 missing values, which is 9.09%\n",
      "Row 184 has 1 missing values, which is 9.09%\n",
      "Row 185 has 1 missing values, which is 9.09%\n",
      "Row 186 has 1 missing values, which is 9.09%\n",
      "Row 187 has 1 missing values, which is 9.09%\n",
      "Row 188 has 1 missing values, which is 9.09%\n",
      "Row 189 has 1 missing values, which is 9.09%\n",
      "Row 190 has 1 missing values, which is 9.09%\n",
      "Row 191 has 1 missing values, which is 9.09%\n",
      "Row 192 has 1 missing values, which is 9.09%\n",
      "Row 193 has 1 missing values, which is 9.09%\n",
      "Row 194 has 1 missing values, which is 9.09%\n",
      "Row 195 has 1 missing values, which is 9.09%\n",
      "Row 196 has 1 missing values, which is 9.09%\n",
      "Row 197 has 1 missing values, which is 9.09%\n",
      "Row 198 has 1 missing values, which is 9.09%\n",
      "Row 199 has 1 missing values, which is 9.09%\n",
      "Row 200 has 1 missing values, which is 9.09%\n",
      "Row 201 has 1 missing values, which is 9.09%\n",
      "Row 202 has 1 missing values, which is 9.09%\n",
      "Row 203 has 1 missing values, which is 9.09%\n",
      "Row 204 has 1 missing values, which is 9.09%\n",
      "Row 205 has 1 missing values, which is 9.09%\n",
      "Row 206 has 1 missing values, which is 9.09%\n",
      "Row 207 has 1 missing values, which is 9.09%\n",
      "Row 208 has 1 missing values, which is 9.09%\n",
      "Row 209 has 1 missing values, which is 9.09%\n",
      "Row 210 has 1 missing values, which is 9.09%\n",
      "Row 211 has 1 missing values, which is 9.09%\n",
      "Row 212 has 1 missing values, which is 9.09%\n",
      "Row 213 has 1 missing values, which is 9.09%\n",
      "Row 214 has 1 missing values, which is 9.09%\n",
      "Row 215 has 1 missing values, which is 9.09%\n",
      "Row 216 has 1 missing values, which is 9.09%\n",
      "Row 217 has 1 missing values, which is 9.09%\n",
      "Row 218 has 1 missing values, which is 9.09%\n",
      "Row 219 has 1 missing values, which is 9.09%\n",
      "Row 220 has 1 missing values, which is 9.09%\n",
      "Row 221 has 1 missing values, which is 9.09%\n",
      "Row 222 has 1 missing values, which is 9.09%\n",
      "Row 223 has 1 missing values, which is 9.09%\n",
      "Row 224 has 1 missing values, which is 9.09%\n",
      "Row 225 has 1 missing values, which is 9.09%\n",
      "Row 226 has 1 missing values, which is 9.09%\n",
      "Row 227 has 1 missing values, which is 9.09%\n",
      "Row 228 has 1 missing values, which is 9.09%\n",
      "Row 229 has 1 missing values, which is 9.09%\n",
      "Row 230 has 1 missing values, which is 9.09%\n",
      "Row 231 has 1 missing values, which is 9.09%\n",
      "Row 232 has 1 missing values, which is 9.09%\n",
      "Row 233 has 1 missing values, which is 9.09%\n",
      "Row 234 has 1 missing values, which is 9.09%\n",
      "Row 235 has 1 missing values, which is 9.09%\n",
      "Row 236 has 1 missing values, which is 9.09%\n",
      "Row 237 has 1 missing values, which is 9.09%\n",
      "Row 238 has 1 missing values, which is 9.09%\n",
      "Row 239 has 1 missing values, which is 9.09%\n",
      "Row 240 has 1 missing values, which is 9.09%\n",
      "Row 241 has 1 missing values, which is 9.09%\n",
      "Row 242 has 1 missing values, which is 9.09%\n",
      "Row 243 has 1 missing values, which is 9.09%\n",
      "Row 244 has 1 missing values, which is 9.09%\n",
      "Row 245 has 1 missing values, which is 9.09%\n",
      "Row 246 has 1 missing values, which is 9.09%\n",
      "Row 247 has 1 missing values, which is 9.09%\n",
      "Row 248 has 1 missing values, which is 9.09%\n",
      "Row 249 has 1 missing values, which is 9.09%\n",
      "Row 250 has 1 missing values, which is 9.09%\n",
      "Row 251 has 1 missing values, which is 9.09%\n",
      "Row 252 has 1 missing values, which is 9.09%\n",
      "Row 253 has 1 missing values, which is 9.09%\n",
      "Row 254 has 1 missing values, which is 9.09%\n",
      "Row 255 has 1 missing values, which is 9.09%\n",
      "Row 256 has 1 missing values, which is 9.09%\n",
      "Row 257 has 1 missing values, which is 9.09%\n",
      "Row 258 has 1 missing values, which is 9.09%\n",
      "Row 259 has 1 missing values, which is 9.09%\n",
      "Row 260 has 1 missing values, which is 9.09%\n",
      "Row 261 has 1 missing values, which is 9.09%\n",
      "Row 262 has 1 missing values, which is 9.09%\n",
      "Row 263 has 1 missing values, which is 9.09%\n",
      "Row 264 has 1 missing values, which is 9.09%\n",
      "Row 265 has 1 missing values, which is 9.09%\n",
      "Row 266 has 1 missing values, which is 9.09%\n",
      "Row 267 has 1 missing values, which is 9.09%\n",
      "Row 268 has 1 missing values, which is 9.09%\n",
      "Row 269 has 1 missing values, which is 9.09%\n",
      "Row 270 has 1 missing values, which is 9.09%\n",
      "Row 271 has 1 missing values, which is 9.09%\n",
      "Row 272 has 1 missing values, which is 9.09%\n",
      "Row 273 has 1 missing values, which is 9.09%\n",
      "Row 274 has 1 missing values, which is 9.09%\n",
      "Row 275 has 1 missing values, which is 9.09%\n",
      "Row 276 has 1 missing values, which is 9.09%\n",
      "Row 277 has 1 missing values, which is 9.09%\n",
      "Row 278 has 1 missing values, which is 9.09%\n",
      "Row 279 has 1 missing values, which is 9.09%\n",
      "Row 280 has 1 missing values, which is 9.09%\n",
      "Row 281 has 1 missing values, which is 9.09%\n"
     ]
    }
   ],
   "source": [
    "# Loop through each row of the DataFrame\n",
    "for index, row in df.iterrows():  \n",
    "    # Check if the current row has any missing values\n",
    "    if row.isnull().sum() > 0:  \n",
    "        # Calculate the percentage of missing values in the current row\n",
    "        percentage_missing = round((row.isnull().sum() / df.shape[1]) * 100, 2)\n",
    "        \n",
    "        # Display the number and percentage of missing values for each row\n",
    "        print(f\"Row {index+1} has {row.isnull().sum()} missing values, which is {percentage_missing}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yX3oGTZw64rf"
   },
   "source": [
    "4. List the number and percentage of missing values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "qcY2EH1U6-Qf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column OT has 1234 missing values, which is 93.77%\n",
      "Column Notes has 1314 missing values, which is 99.85%\n"
     ]
    }
   ],
   "source": [
    "# Loop through each column in the DataFrame\n",
    "for column in df.columns:  \n",
    "    # Check if the current column has any missing values\n",
    "    if (df[column].isnull().sum()) > 0:  \n",
    "        # Calculate the percentage of missing values in the current column\n",
    "        percentage_missing = round((((df[column].isnull().sum()) / df.shape[0]) * 100), 2)\n",
    "        \n",
    "        # Display the number and percentage of missing values for each column\n",
    "        print(f\"Column {column} has {df[column].isnull().sum()} missing values, which is {percentage_missing}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCaZ4Haq7JAA"
   },
   "source": [
    "5. If there are missing values for a column, forward fill the missing values. Does it make sense to forward or backward fill the missing values for each row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "y3XAH7H-8GkZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total % of missing values in dataframe: 2.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mw/4snkpx0970n_6rz3jtvq4yxr0000gn/T/ipykernel_2391/148989059.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Filling all the missing values in the DataFrame by forward filling\n",
    "df = df.fillna(method='ffill')\n",
    "\n",
    "# Calculating the total percentage of missing values in the entire DataFrame and displaying it\n",
    "print(f\"Total % of missing values in dataframe: {round(((df.isnull().sum().sum())/(df.shape[0] * df.shape[1])) * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ In this case, it does not make sense to forward fill or backward fill this dataframe because the preceding value does not affect the missing entires. However, if the puprose is to just fill up all uncovered values, then it is best in this case to forward fill since there are less null values (23) than there would have been in backward fill (24)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-EkThQluo4H"
   },
   "source": [
    "6. Group by the Visitor/Neutral teams. Compute the aveage points (PTS) for each team playing as visiting team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "M4qAt722GTF7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visitor/Neutral\n",
      "Atlanta Hawks             101.717391\n",
      "Boston Celtics            104.022727\n",
      "Brooklyn Nets              98.365854\n",
      "Charlotte Hornets         100.266667\n",
      "Chicago Bulls             101.463415\n",
      "Cleveland Cavaliers       101.384615\n",
      "Dallas Mavericks           99.318182\n",
      "Denver Nuggets            100.121951\n",
      "Detroit Pistons            98.720930\n",
      "Golden State Warriors     112.098039\n",
      "Houston Rockets           105.568182\n",
      "Indiana Pacers            100.622222\n",
      "Los Angeles Clippers      103.340909\n",
      "Los Angeles Lakers         97.878049\n",
      "Memphis Grizzlies          95.162791\n",
      "Miami Heat                 96.000000\n",
      "Milwaukee Bucks            97.243902\n",
      "Minnesota Timberwolves    103.317073\n",
      "New Orleans Pelicans       99.512195\n",
      "New York Knicks            97.878049\n",
      "Oklahoma City Thunder     109.600000\n",
      "Orlando Magic              99.609756\n",
      "Philadelphia 76ers         96.756098\n",
      "Phoenix Suns               98.634146\n",
      "Portland Trail Blazers    102.170213\n",
      "Sacramento Kings          105.609756\n",
      "San Antonio Spurs         101.891304\n",
      "Toronto Raptors            98.200000\n",
      "Utah Jazz                  96.804878\n",
      "Washington Wizards        102.121951\n",
      "Name: Visitor PTS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Grouping the DataFrame by the 'Visitor/Neutral' column and calculating the average points scored by each visiting team\n",
    "average_pts_visiting_team = df.groupby('Visitor/Neutral')['Visitor PTS'].mean()\n",
    "\n",
    "# Printing the result\n",
    "print(average_pts_visiting_team)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpsHX6Nxv0Uu"
   },
   "source": [
    "7. Add a new column 'VisitorWon' which has True for the Visiting team won and False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "2lkfaO5AGVHZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       False\n",
      "1        True\n",
      "2       False\n",
      "3        True\n",
      "4       False\n",
      "        ...  \n",
      "1311    False\n",
      "1312     True\n",
      "1313     True\n",
      "1314    False\n",
      "1315     True\n",
      "Name: VisitorWon, Length: 1316, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Creating a new column 'VisitorWon' to check if the visiting team won the game\n",
    "df['VisitorWon'] = df['Visitor PTS'] > df['Home PTS']\n",
    "\n",
    "# Printing the 'VisitorWon' column\n",
    "print(df['VisitorWon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhAzO3W9whAl"
   },
   "source": [
    "8. Compute the rate of VisitorWon for each team playing away during the 2016 season, in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "bEOGsemHGXZ5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visitor/Neutral\n",
      "San Antonio Spurs         67.741935\n",
      "Golden State Warriors     67.647059\n",
      "Cleveland Cavaliers       63.888889\n",
      "Oklahoma City Thunder     56.756757\n",
      "Toronto Raptors           50.000000\n",
      "Los Angeles Clippers      50.000000\n",
      "Washington Wizards        46.153846\n",
      "Miami Heat                45.945946\n",
      "Charlotte Hornets         45.454545\n",
      "Indiana Pacers            44.827586\n",
      "Atlanta Hawks             43.333333\n",
      "Portland Trail Blazers    42.307692\n",
      "Utah Jazz                 42.307692\n",
      "Sacramento Kings          42.307692\n",
      "Detroit Pistons           42.307692\n",
      "Houston Rockets           41.379310\n",
      "Dallas Mavericks          40.740741\n",
      "Boston Celtics            37.931034\n",
      "Chicago Bulls             37.931034\n",
      "Denver Nuggets            34.782609\n",
      "Memphis Grizzlies         34.615385\n",
      "Minnesota Timberwolves    32.000000\n",
      "New York Knicks           29.166667\n",
      "Milwaukee Bucks           27.272727\n",
      "New Orleans Pelicans      26.086957\n",
      "Phoenix Suns              20.833333\n",
      "Orlando Magic             18.518519\n",
      "Brooklyn Nets             16.000000\n",
      "Los Angeles Lakers         5.263158\n",
      "Philadelphia 76ers         5.000000\n",
      "Name: VisitorWon, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Filtering the DataFrame to include only rows where the 'Date' column ends with '2016'\n",
    "df_2016 = df[df['Date'].str[-4:] == '2016']\n",
    "\n",
    "# Grouping the filtered DataFrame by the 'Visitor/Neutral' column and calculating the average of the 'VisitorWon' column for each visiting team\n",
    "visitor_win_rate = df_2016.groupby('Visitor/Neutral')['VisitorWon'].mean()\n",
    "\n",
    "# Sorting the win rates in descending order and printing the result to see the win %age for each visiting team during the 2016 season\n",
    "print(f\"{visitor_win_rate.sort_values(ascending=False)*100}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26_L9FB6yGWk"
   },
   "source": [
    "9. Define a function 'top' that returns the top two rows based on a given col value. List each team's top 2 winning visiting games in which the team got top 2 highest points. Order the results by team names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "IsJujYF_GalQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Date Start (ET)         Visitor/Neutral  Visitor PTS  \\\n",
      "0    Thu Jan 7 2016      7:00p           Atlanta Hawks          126   \n",
      "1    Wed Feb 3 2016      7:00p           Atlanta Hawks          124   \n",
      "2   Mon Feb 22 2016      8:00p          Boston Celtics          122   \n",
      "3   Sun Feb 21 2016      5:00p          Boston Celtics          121   \n",
      "4    Fri Mar 4 2016      9:00p           Brooklyn Nets          121   \n",
      "5    Sat Mar 5 2016      8:00p           Brooklyn Nets          118   \n",
      "6   Mon Jan 25 2016     10:00p       Charlotte Hornets          129   \n",
      "7   Fri Dec 11 2015      8:00p       Charlotte Hornets          123   \n",
      "8   Mon Apr 11 2016      8:00p           Chicago Bulls          121   \n",
      "9   Wed Oct 28 2015      7:30p           Chicago Bulls          115   \n",
      "10   Fri Jan 8 2016      8:00p     Cleveland Cavaliers          125   \n",
      "11   Wed Jan 6 2016      7:00p     Cleveland Cavaliers          121   \n",
      "12  Wed Dec 23 2015      7:30p        Dallas Mavericks          119   \n",
      "13  Fri Mar 25 2016     10:30p        Dallas Mavericks          120   \n",
      "14   Tue Nov 3 2015     10:30p          Denver Nuggets          120   \n",
      "15  Mon Mar 14 2016      7:30p          Denver Nuggets          119   \n",
      "16  Fri Dec 18 2015      8:00p         Detroit Pistons          147   \n",
      "17  Sat Mar 12 2016      7:00p         Detroit Pistons          125   \n",
      "18  Fri Nov 27 2015      9:30p   Golden State Warriors          135   \n",
      "19  Sat Oct 31 2015      7:30p   Golden State Warriors          134   \n",
      "20  Mon Jan 18 2016     10:30p         Houston Rockets          132   \n",
      "21  Mon Apr 11 2016      8:00p         Houston Rockets          129   \n",
      "22  Sun Jan 17 2016      8:00p          Indiana Pacers          126   \n",
      "23  Tue Nov 24 2015      7:00p          Indiana Pacers          123   \n",
      "24  Wed Feb 10 2016      7:30p    Los Angeles Clippers          134   \n",
      "25  Wed Dec 30 2015      7:00p    Los Angeles Clippers          122   \n",
      "26   Wed Dec 9 2015      8:00p      Los Angeles Lakers          122   \n",
      "27  Wed Feb 24 2016      8:00p      Los Angeles Lakers          119   \n",
      "28   Tue Dec 1 2015      8:00p       Memphis Grizzlies          113   \n",
      "29  Sun Nov 15 2015      3:30p       Memphis Grizzlies          114   \n",
      "30  Fri Mar 11 2016      8:00p              Miami Heat          118   \n",
      "31  Fri Feb 19 2016      8:00p              Miami Heat          115   \n",
      "32  Tue Dec 29 2015      8:00p         Milwaukee Bucks          123   \n",
      "33  Thu Dec 31 2015      6:00p         Milwaukee Bucks          120   \n",
      "34  Fri Mar 25 2016      7:00p  Minnesota Timberwolves          132   \n",
      "35   Tue Apr 5 2016     10:30p  Minnesota Timberwolves          124   \n",
      "36  Sun Dec 20 2015      8:00p    New Orleans Pelicans          130   \n",
      "37  Wed Mar 16 2016     10:00p    New Orleans Pelicans          123   \n",
      "38   Wed Mar 9 2016      9:00p         New York Knicks          128   \n",
      "39  Wed Oct 28 2015      8:00p         New York Knicks          122   \n",
      "40  Fri Oct 30 2015      7:00p   Oklahoma City Thunder          139   \n",
      "41  Mon Feb 29 2016     10:00p   Oklahoma City Thunder          131   \n",
      "42   Mon Feb 8 2016      8:00p           Orlando Magic          117   \n",
      "43  Tue Feb 23 2016      7:00p           Orlando Magic          124   \n",
      "44  Fri Nov 27 2015      8:00p      Philadelphia 76ers          114   \n",
      "45  Sun Feb 28 2016      6:00p      Philadelphia 76ers          116   \n",
      "46   Thu Apr 7 2016      8:00p            Phoenix Suns          124   \n",
      "47   Wed Dec 2 2015      7:30p            Phoenix Suns          122   \n",
      "48  Wed May 11 2016     10:30p  Portland Trail Blazers          121   \n",
      "49  Sun Mar 20 2016      4:00p  Portland Trail Blazers          120   \n",
      "50  Wed Nov 25 2015      8:00p        Sacramento Kings          129   \n",
      "51  Mon Nov 23 2015      7:00p        Sacramento Kings          122   \n",
      "52   Mon Jan 4 2016      8:00p       San Antonio Spurs          123   \n",
      "53   Mon Dec 7 2015      7:00p       San Antonio Spurs          119   \n",
      "54  Mon Feb 22 2016      7:30p         Toronto Raptors          122   \n",
      "55  Wed Nov 11 2015      7:00p         Toronto Raptors          119   \n",
      "56   Tue Feb 9 2016      8:30p               Utah Jazz          121   \n",
      "57  Mon Jan 18 2016      2:00p               Utah Jazz          119   \n",
      "58  Sat Jan 30 2016      8:00p      Washington Wizards          123   \n",
      "59  Mon Apr 11 2016      7:30p      Washington Wizards          120   \n",
      "\n",
      "              Home/Neutral  Home PTS Score Type   OT  Attend.  \\\n",
      "0       Philadelphia 76ers        98  Box Score  2OT    12611   \n",
      "1       Philadelphia 76ers        86  Box Score   OT    10429   \n",
      "2   Minnesota Timberwolves       124  Box Score   OT    11639   \n",
      "3           Denver Nuggets       101  Box Score  2OT    16065   \n",
      "4           Denver Nuggets       120  Box Score   OT    14163   \n",
      "5   Minnesota Timberwolves       132  Box Score   OT    15987   \n",
      "6         Sacramento Kings       128  Box Score  2OT    16991   \n",
      "7        Memphis Grizzlies        99  Box Score  2OT    17111   \n",
      "8     New Orleans Pelicans       116  Box Score   OT    16867   \n",
      "9            Brooklyn Nets       100  Box Score  NaN    17732   \n",
      "10  Minnesota Timberwolves        99  Box Score  2OT    16768   \n",
      "11      Washington Wizards       115  Box Score  2OT    20356   \n",
      "12           Brooklyn Nets       118  Box Score   OT    15994   \n",
      "13   Golden State Warriors       128  Box Score  2OT    19596   \n",
      "14      Los Angeles Lakers       109  Box Score   OT    18997   \n",
      "15              Miami Heat       124  Box Score   OT    19744   \n",
      "16           Chicago Bulls       144  Box Score  4OT    21534   \n",
      "17      Philadelphia 76ers       111  Box Score   OT    16087   \n",
      "18            Phoenix Suns       116  Box Score   OT    18055   \n",
      "19    New Orleans Pelicans       120  Box Score   OT    18406   \n",
      "20    Los Angeles Clippers       140  Box Score   OT    19060   \n",
      "21  Minnesota Timberwolves       105  Box Score   OT    14983   \n",
      "22          Denver Nuggets       129  Box Score   OT    11104   \n",
      "23      Washington Wizards       106  Box Score   OT    15486   \n",
      "24          Boston Celtics       139  Box Score   OT    18186   \n",
      "25       Charlotte Hornets       117  Box Score   OT    19145   \n",
      "26  Minnesota Timberwolves       123  Box Score   OT    18076   \n",
      "27       Memphis Grizzlies       128  Box Score   OT    18119   \n",
      "28    New Orleans Pelicans       104  Box Score   OT    16020   \n",
      "29  Minnesota Timberwolves       106  Box Score   OT    12086   \n",
      "30           Chicago Bulls        96  Box Score   OT    22067   \n",
      "31           Atlanta Hawks       111  Box Score   OT    19043   \n",
      "32   Oklahoma City Thunder       131  Box Score   OT    18203   \n",
      "33          Indiana Pacers       116  Box Score   OT    16348   \n",
      "34      Washington Wizards       129  Box Score  2OT    20356   \n",
      "35   Golden State Warriors       117  Box Score   OT    19596   \n",
      "36          Denver Nuggets       125  Box Score  4OT    13857   \n",
      "37        Sacramento Kings       108  Box Score   OT    17086   \n",
      "38            Phoenix Suns        97  Box Score   OT    17105   \n",
      "39         Milwaukee Bucks        97  Box Score  NaN    18717   \n",
      "40           Orlando Magic       136  Box Score  2OT    18846   \n",
      "41        Sacramento Kings       116  Box Score   OT    17317   \n",
      "42           Atlanta Hawks       110  Box Score   OT    13057   \n",
      "43      Philadelphia 76ers       115  Box Score   OT    13745   \n",
      "44         Houston Rockets       116  Box Score   OT    17306   \n",
      "45           Orlando Magic       130  Box Score   OT    16168   \n",
      "46         Houston Rockets       115  Box Score   OT    18227   \n",
      "47         Detroit Pistons       127  Box Score   OT    13985   \n",
      "48   Golden State Warriors       125  Box Score   OT    19596   \n",
      "49        Dallas Mavericks       132  Box Score   OT    20351   \n",
      "50         Milwaukee Bucks       118  Box Score   OT    14120   \n",
      "51       Charlotte Hornets       127  Box Score   OT    14163   \n",
      "52         Milwaukee Bucks        98  Box Score   OT    14718   \n",
      "53      Philadelphia 76ers        68  Box Score   OT    14449   \n",
      "54         New York Knicks        95  Box Score   OT    19812   \n",
      "55      Philadelphia 76ers       103  Box Score   OT    12744   \n",
      "56        Dallas Mavericks       119  Box Score   OT    19394   \n",
      "57       Charlotte Hornets       124  Box Score  2OT    17459   \n",
      "58         Houston Rockets       122  Box Score   OT    18320   \n",
      "59           Brooklyn Nets       111  Box Score   OT    14653   \n",
      "\n",
      "                    Notes  VisitorWon  \n",
      "0   at Mexico City Mexico        True  \n",
      "1       at London England        True  \n",
      "2       at London England       False  \n",
      "3       at London England        True  \n",
      "4       at London England        True  \n",
      "5       at London England       False  \n",
      "6       at London England        True  \n",
      "7   at Mexico City Mexico        True  \n",
      "8       at London England        True  \n",
      "9                     NaN        True  \n",
      "10  at Mexico City Mexico        True  \n",
      "11  at Mexico City Mexico        True  \n",
      "12  at Mexico City Mexico        True  \n",
      "13      at London England       False  \n",
      "14                    NaN        True  \n",
      "15      at London England       False  \n",
      "16  at Mexico City Mexico        True  \n",
      "17      at London England        True  \n",
      "18                    NaN        True  \n",
      "19                    NaN        True  \n",
      "20      at London England       False  \n",
      "21      at London England        True  \n",
      "22      at London England       False  \n",
      "23                    NaN        True  \n",
      "24      at London England       False  \n",
      "25  at Mexico City Mexico        True  \n",
      "26  at Mexico City Mexico       False  \n",
      "27      at London England       False  \n",
      "28                    NaN        True  \n",
      "29                    NaN        True  \n",
      "30      at London England        True  \n",
      "31      at London England        True  \n",
      "32  at Mexico City Mexico       False  \n",
      "33  at Mexico City Mexico        True  \n",
      "34      at London England        True  \n",
      "35      at London England        True  \n",
      "36  at Mexico City Mexico        True  \n",
      "37      at London England        True  \n",
      "38      at London England        True  \n",
      "39                    NaN        True  \n",
      "40                    NaN        True  \n",
      "41      at London England        True  \n",
      "42      at London England        True  \n",
      "43      at London England        True  \n",
      "44                    NaN       False  \n",
      "45      at London England       False  \n",
      "46      at London England        True  \n",
      "47                    NaN       False  \n",
      "48      at London England       False  \n",
      "49      at London England       False  \n",
      "50                    NaN        True  \n",
      "51                    NaN       False  \n",
      "52  at Mexico City Mexico        True  \n",
      "53  at Mexico City Mexico        True  \n",
      "54      at London England        True  \n",
      "55                    NaN        True  \n",
      "56      at London England        True  \n",
      "57      at London England       False  \n",
      "58      at London England        True  \n",
      "59      at London England        True  \n"
     ]
    }
   ],
   "source": [
    "# Function to get the top 'n' rows based on the column 'col'\n",
    "def top(df, col, n=2):\n",
    "    return df.nlargest(n, col)\n",
    "\n",
    "# Group the DataFrame by visiting teams\n",
    "grouped = df.groupby('Visitor/Neutral')\n",
    "\n",
    "# List to store top games for each team\n",
    "results = []\n",
    "\n",
    "# Loop through each team and get their top 2 games by points\n",
    "for team_name, group in grouped:\n",
    "    top_rows = top(group, 'Visitor PTS', n=2)\n",
    "    results.append(top_rows)\n",
    "\n",
    "# Combine all top rows into one DataFrame\n",
    "top_visiting_games = pd.concat(results)\n",
    "\n",
    "# Sort by team names and reset the index\n",
    "top_visiting_games = top_visiting_games.sort_values(by='Visitor/Neutral').reset_index(drop=True)\n",
    "\n",
    "# Print the top 2 games for each visiting team\n",
    "print(top_visiting_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMfpkRGjCs3r"
   },
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovNrTgXwCuhC"
   },
   "source": [
    "1. Download and upload the Cleaned_Laptop_data.csv. Create a DataFrame df from the data set. Show information of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "tFoLDrcYGcTA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of Dataframe: Index(['brand', 'model', 'processor_brand', 'processor_name',\n",
      "       'processor_gnrtn', 'ram_gb', 'ram_type', 'ssd', 'hdd', 'os', 'os_bit',\n",
      "       'graphic_card_gb', 'weight', 'display_size', 'warranty', 'Touchscreen',\n",
      "       'msoffice', 'latest_price', 'old_price', 'discount', 'star_rating',\n",
      "       'ratings', 'reviews'],\n",
      "      dtype='object')\n",
      "\n",
      "First five rows of Dataframe:   brand     model processor_brand processor_name processor_gnrtn ram_gb  \\\n",
      "0  ASUS   Celeron           Intel   Celeron Dual         Missing      4   \n",
      "1  ASUS  VivoBook           Intel        Core i3            10th      8   \n",
      "2  ASUS  Vivobook           Intel        Core i3            10th      8   \n",
      "3    HP      Core           Intel        Core i3            11th      8   \n",
      "4    HP      Core           Intel        Core i5            11th      8   \n",
      "\n",
      "  ram_type  ssd   hdd       os  ...  display_size  warranty Touchscreen  \\\n",
      "0     DDR4    0  1024  Windows  ...          15.6         1          No   \n",
      "1     DDR4  512     0  Windows  ...          15.6         1          No   \n",
      "2     DDR4    0  1024  Windows  ...          14.1         1          No   \n",
      "3     DDR4  512     0  Windows  ...          15.6         1          No   \n",
      "4     DDR4  512     0  Windows  ...          15.6         0          No   \n",
      "\n",
      "  msoffice  latest_price old_price discount  star_rating  ratings  reviews  \n",
      "0       No         23990     26990       11          3.8    15279     1947  \n",
      "1       No         37990     50990       25          4.3      990      108  \n",
      "2       No         32890     46990       30          3.9       28        4  \n",
      "3      Yes         42990     57330       25          4.4      158       18  \n",
      "4       No         54990     70171       21          4.2      116       15  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "               ssd          hdd      os_bit  graphic_card_gb    warranty  \\\n",
      "count   896.000000   896.000000  896.000000       896.000000  896.000000   \n",
      "mean    431.750000   190.857143   59.178571         1.198661    0.691964   \n",
      "std     316.436824   401.181158   11.453644         2.057454    0.606282   \n",
      "min       0.000000     0.000000   32.000000         0.000000    0.000000   \n",
      "25%     256.000000     0.000000   64.000000         0.000000    0.000000   \n",
      "50%     512.000000     0.000000   64.000000         0.000000    1.000000   \n",
      "75%     512.000000     0.000000   64.000000         2.000000    1.000000   \n",
      "max    3072.000000  2048.000000   64.000000         8.000000    3.000000   \n",
      "\n",
      "        latest_price      old_price    discount  star_rating       ratings  \\\n",
      "count     896.000000     896.000000  896.000000   896.000000    896.000000   \n",
      "mean    76309.860491   88134.154018   18.527902     2.980469    367.391741   \n",
      "std     46613.354368   55719.645554   10.508486     1.965254   1106.309355   \n",
      "min     13990.000000       0.000000    0.000000     0.000000      0.000000   \n",
      "25%     45490.000000   54940.500000   11.000000     0.000000      0.000000   \n",
      "50%     63494.000000   78052.500000   19.000000     4.100000     19.000000   \n",
      "75%     89090.000000  111019.500000   26.000000     4.400000    179.500000   \n",
      "max    441990.000000  377798.000000   57.000000     5.000000  15279.000000   \n",
      "\n",
      "           reviews  \n",
      "count   896.000000  \n",
      "mean     46.152902  \n",
      "std     136.079586  \n",
      "min       0.000000  \n",
      "25%       0.000000  \n",
      "50%       3.000000  \n",
      "75%      23.250000  \n",
      "max    1947.000000  \n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"/Users/mustafabookwala/Desktop/Drexel/Pre-Junior/Fall 2024/INFO 212/Week 8/Cleaned_Laptop_data(3).csv\")  # Loading the dataframe\n",
    "print(f\"Columns of Dataframe: {df2.columns}\\n\")  # Displaying Column Names\n",
    "print(f\"First five rows of Dataframe: {df2.head()}\\n\")  # Displaying first five entries\n",
    "print(df2.describe())  # Displaying statistical information about numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_U7joBHE7kJy"
   },
   "source": [
    "2. Forward fill missing values for each column. Ensure there is no missing value after the filling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "O0j3QsgU7pbS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in dataframe before Forward Fill: 51\n",
      "Number of null values in dataframe after Forward Fill: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mw/4snkpx0970n_6rz3jtvq4yxr0000gn/T/ipykernel_2391/1185669805.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df2 = df2.fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Print the total number of null values in the DataFrame before filling\n",
    "print(f\"Number of null values in dataframe before Forward Fill: {df2.isnull().sum().sum()}\")\n",
    "\n",
    "# Fill missing values using forward fill\n",
    "df2 = df2.fillna(method='ffill')\n",
    "\n",
    "# Print the total number of null values in the DataFrame after filling\n",
    "print(f\"Number of null values in dataframe after Forward Fill: {df2.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCG8y9p4DE-L"
   },
   "source": [
    "3. Create a pivot table containing the means of latest_price and ratings indexed by brand, model, and os. Put os on columns and also compute the margins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "x99kSG2fGfqh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       latest_price                               \\\n",
      "os                              Mac        Missing       Windows   \n",
      "brand     model                                                    \n",
      "ALIENWARE Core                  NaN  257365.000000           NaN   \n",
      "APPLE     2020        107740.000000            NaN           NaN   \n",
      "          2021        236156.666667            NaN           NaN   \n",
      "          MacBook     140640.000000            NaN           NaN   \n",
      "ASUS      AMD                   NaN            NaN  80990.000000   \n",
      "...                             ...            ...           ...   \n",
      "lenovo    Ideapad               NaN   72990.000000           NaN   \n",
      "          Yoga                  NaN  137494.000000           NaN   \n",
      "realme    Book                  NaN            NaN  47494.500000   \n",
      "          Book(Slim)            NaN            NaN  56994.500000   \n",
      "All                   151707.857143   85654.777778  72812.400754   \n",
      "\n",
      "                                         ratings                           \\\n",
      "os                              All          Mac     Missing      Windows   \n",
      "brand     model                                                             \n",
      "ALIENWARE Core        257365.000000          NaN   10.000000          NaN   \n",
      "APPLE     2020        107740.000000  2143.250000         NaN          NaN   \n",
      "          2021        236156.666667    35.500000         NaN          NaN   \n",
      "          MacBook     140640.000000  1175.142857         NaN          NaN   \n",
      "ASUS      AMD          80990.000000          NaN         NaN     0.000000   \n",
      "...                             ...          ...         ...          ...   \n",
      "lenovo    Ideapad      72990.000000          NaN  204.000000          NaN   \n",
      "          Yoga        137494.000000          NaN   39.500000          NaN   \n",
      "realme    Book         47494.500000          NaN         NaN  6352.000000   \n",
      "          Book(Slim)   56994.500000          NaN         NaN  3470.000000   \n",
      "All                    76309.860491  1207.535714  767.319444   301.664573   \n",
      "\n",
      "                                   \n",
      "os                            All  \n",
      "brand     model                    \n",
      "ALIENWARE Core          10.000000  \n",
      "APPLE     2020        2143.250000  \n",
      "          2021          35.500000  \n",
      "          MacBook     1175.142857  \n",
      "ASUS      AMD            0.000000  \n",
      "...                           ...  \n",
      "lenovo    Ideapad      204.000000  \n",
      "          Yoga          39.500000  \n",
      "realme    Book        6352.000000  \n",
      "          Book(Slim)  3470.000000  \n",
      "All                    367.391741  \n",
      "\n",
      "[144 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a pivot table to calculate the mean of 'latest_price' and 'ratings'. Group by 'brand' and 'model', with 'os' as columns\n",
    "pivot_table = pd.pivot_table(\n",
    "    df2,\n",
    "    values=['latest_price', 'ratings'],\n",
    "    index=['brand', 'model'],            \n",
    "    columns=['os'],                      \n",
    "    aggfunc='mean',                      \n",
    "    margins=True,                        \n",
    "    margins_name='All'                   \n",
    ")\n",
    "\n",
    "# Print the pivot table\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQR2fSaBDnLL"
   },
   "source": [
    "4. Using pd.crosstab() to compute the numbers of laptops by brand and os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "QVhgaoIYDsDB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os         Mac  Missing  Windows\n",
      "brand                           \n",
      "ALIENWARE    0        4        0\n",
      "APPLE       28        0        0\n",
      "ASUS         0       16      238\n",
      "Avita        0        0       18\n",
      "DELL         0        5      149\n",
      "HP           0       14      128\n",
      "Infinix      0        0        4\n",
      "LG           0        0        5\n",
      "Lenovo       0       11      137\n",
      "MICROSOFT    0        0        3\n",
      "MSI          0        8       44\n",
      "Mi           0        0        2\n",
      "Nokia        0        0        4\n",
      "RedmiBook    0        0        3\n",
      "SAMSUNG      0        0        1\n",
      "Smartron     0        0        3\n",
      "Vaio         0        0        5\n",
      "acer         0       11       47\n",
      "iball        0        0        1\n",
      "lenovo       0        3        0\n",
      "realme       0        0        4\n"
     ]
    }
   ],
   "source": [
    "# Create a crosstab to count the occurrences of each 'os' for every 'brand'\n",
    "crosstab_result = pd.crosstab(df2['brand'], df2['os'])\n",
    "\n",
    "# Print the crosstab\n",
    "print(crosstab_result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
